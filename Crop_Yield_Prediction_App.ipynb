{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwu6Os2tDoOV"
      },
      "source": [
        "# CSC 310 Final Project: Crop Yield Prediction App"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmzvVs7FDux1"
      },
      "source": [
        "Group Members: Ryan Jensen, Timothy Hourihan\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da7JQBsaiAie"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3DhlKemD0K9"
      },
      "source": [
        "#### Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WELcs2Hkhbnd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import plotly.express as px\n",
        "# from google.colab import drive # Uncomment if you are running in a Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysUQyDiSIoVv"
      },
      "source": [
        "### Reading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvOIn8YCh-lE",
        "outputId": "1e88ac28-92f6-4639-fee7-1af1ae4c2f8f"
      },
      "outputs": [],
      "source": [
        "# Uncomment below if you are running in Google Colab. You should have the dataset stored on your drive. (Note: You can't run Gradio in Google Colab)\n",
        "# drive.mount('/content/drive')\n",
        "# df=pd.read_csv(\"/content/drive/MyDrive/yield_df.csv\")\n",
        "\n",
        "# The following code is if you are running this locally.\n",
        "df = pd.read_csv(\"data/yield_df.csv\" )\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ROjnQQtPFJSG",
        "outputId": "88038c89-30e3-4f91-ae00-0b0d28ea622d"
      },
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "280TLO8Sjd3y"
      },
      "source": [
        "#### Removing the unnamed column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJNaJ36Tjhw3",
        "outputId": "6a7278e5-fd7c-4aad-e4e6-dc98b65b9322"
      },
      "outputs": [],
      "source": [
        "df.drop(\"Unnamed: 0\", axis=1,inplace=True)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuX_GJcDk7Yl"
      },
      "source": [
        "#### Changing column names to fit our project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "L_g9hbGlk_T3",
        "outputId": "1878ded1-1dfe-4f2b-984a-4e5296d4a670"
      },
      "outputs": [],
      "source": [
        "df = df.rename(columns = {\"Area\":\"country\"})\n",
        "df = df.rename(columns = {\"Item\":\"crop\"})\n",
        "df = df.rename(columns = {\"Year\":\"year\"})\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uka7fYt7l-dO",
        "outputId": "211bdcf1-4671-4182-e2d1-d0deaae4c0dc"
      },
      "outputs": [],
      "source": [
        "df.isna().sum(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Top 10 Countries with Highest Yield"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.groupby(['country'],sort=True)['hg/ha_yield'].sum().nlargest(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "India and Brazil has far and beyond the highest yield, so it's important to note their average temperatures, rainfall, and pesticide use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_india = df[df['country'] == 'India']\n",
        "df_india.head(10)\n",
        "df_india.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "India has an average of 1083 mm rainfall, 48459 tonnes of pesticide, and a 26 degree celsius temperature to produce the highest yield by a large margin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_india = df[df['country'] == 'Brazil']\n",
        "df_india.head(10)\n",
        "df_india.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Brazil has an average of 1761 mm rainfall, 189736 tonnes of pesticide, and a 22.7 degree celsius temperature to produce the second highest yield."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Histograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.hist(figsize=(5,10));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The majority of pesticide usage according to the histograms is actually close to none. We know that India and Brazil use a lot of pesticide and have the two highest yields, so pesticide use is an important variable here.\n",
        "\n",
        "The majority of rainfall seems to slow down after 2000mm, with most of the rainfall coming before 2000mm\n",
        "\n",
        "Average temperature is around 25 degrees celsius\n",
        "\n",
        "The overall yield is also close to none in most cases, which confirms the validity of the data set since conditions have to be perfect to have a good yield to harvest/sell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scatter Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.pairplot(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "None of these scatter plots in the scatter matrix shows an incredibly strong correlation between any two column, so no deletion is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Heat Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cor = df.select_dtypes(['int64','float64']).corr()\n",
        "sns.heatmap(cor,cmap = 'YlOrRd',annot = True)\n",
        "plt.title('Heatmap')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This heat map further shows that there isn't really a very strong correlation with any of the columns, so no deletion required.\n",
        "\n",
        "While there isn't a strong correlation, we can see that average rain_fall and average_temp can affect eachother. This makes sense because countries with a lot of rain fall typically have slightly cooler climates and vice versa. However, they are not dependent on eachother so we have no need to alter any of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6yRLPVGEDPu"
      },
      "source": [
        "## Building Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjyWyMh4IdZ0"
      },
      "source": [
        "#### Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Wlx_7WaIa8q"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7bg9x7XJH7Q"
      },
      "source": [
        "#### Preparing the data for moedeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQZC5fCGJM0Q"
      },
      "outputs": [],
      "source": [
        "# Separating dataset into features and target\n",
        "X = df.drop('hg/ha_yield', axis=1)\n",
        "y = df['hg/ha_yield']\n",
        "\n",
        "# Encoding categorical data\n",
        "label_encoders = {}\n",
        "for column in ['country', 'crop']:\n",
        "    le = LabelEncoder()\n",
        "    X[column] = le.fit_transform(X[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "# Splitting the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D99l1AMLN1W"
      },
      "source": [
        "#### Training and evaluating models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "poI2wvPEKhla",
        "outputId": "ec8e7714-38f6-4a29-b57b-b69ef3c529b5"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "    ('Linear Regression', LinearRegression()),\n",
        "    ('Gradient Boost', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)),\n",
        "    ('XGBoost', XGBRegressor(random_state=42)),\n",
        "]\n",
        "\n",
        "results = []\n",
        "fig, axs = plt.subplots(len(models), figsize=(10, 20))\n",
        "\n",
        "for idx, (name, model) in enumerate(models):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = model.score(X_test, y_test)\n",
        "    MSE = mean_squared_error(y_test, y_pred)\n",
        "    R2_score = r2_score(y_test, y_pred)\n",
        "    results.append((name, accuracy, MSE, R2_score))\n",
        "\n",
        "    # Plotting\n",
        "    axs[idx].scatter(y_test, y_pred, s=10, color='#1f77b4')  # Blue color\n",
        "    axs[idx].plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='#ff7f0e', linewidth=2)  # Orange color\n",
        "    axs[idx].set_title(f'{name} Evaluation')\n",
        "    axs[idx].set_xlabel('Actual Values')\n",
        "    axs[idx].set_ylabel('Predicted Values')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Displaying results in a DataFrame\n",
        "df_results = pd.DataFrame(results, columns=['Model', 'Accuracy', 'MSE', 'R2_score'])\n",
        "display(df_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH-0JDWHMHKu"
      },
      "source": [
        "#### KFold Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0thMJP2yMGPA",
        "outputId": "c95c98b3-6e3d-4dbb-a058-838060fb66bf"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "models = [\n",
        "    ('Linear Regression', LinearRegression()),\n",
        "    ('Gradient Boost', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)),\n",
        "    ('XGBoost', XGBRegressor(random_state=42)),\n",
        "    ('KNN', KNeighborsRegressor(n_neighbors=5)),\n",
        "    ('Decision Tree', DecisionTreeRegressor(random_state=42))\n",
        "]\n",
        "\n",
        "for name, model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = model.score(X_test, y_test)\n",
        "    MSE = mean_squared_error(y_test, y_pred)\n",
        "    MAE = mean_absolute_error(y_test, y_pred)\n",
        "    MAPE = mean_absolute_percentage_error(y_test, y_pred)\n",
        "    R2_score = r2_score(y_test, y_pred)\n",
        "    results.append((name, accuracy, MSE, MAE, MAPE, R2_score))\n",
        "\n",
        "    # KFold Validation\n",
        "    kf = KFold(n_splits=5, shuffle=True)\n",
        "    scores = cross_val_score(model, X, y, cv=kf)\n",
        "    mean_score = np.mean(scores)\n",
        "    print(f\"{name} - Mean CV Score: {mean_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Deployment with Gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Defining a Predict Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_yield(crop_type, rainfall, country, pesticides, temperature):\n",
        "    try:\n",
        "        # Convert inputs to the correct data types\n",
        "        rainfall = float(rainfall)\n",
        "        pesticides = float(pesticides)\n",
        "        temperature = float(temperature)\n",
        "\n",
        "        # Apply the same LabelEncoder transformations as during model training\n",
        "        encoded_crop = label_encoders['crop'].transform([crop_type])[0]\n",
        "        encoded_country = label_encoders['country'].transform([country])[0]\n",
        "\n",
        "        # Use a default year, 2000 is good\n",
        "        default_year = 2000\n",
        "\n",
        "        # Create a DataFrame for the input with the correct column order\n",
        "        input_data = pd.DataFrame([[encoded_country, encoded_crop, default_year, rainfall, pesticides, temperature]],\n",
        "                                  columns=['country', 'crop', 'year', 'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp'])\n",
        "\n",
        "        # Make a prediction\n",
        "        prediction = xgb_model.predict(input_data)[0]\n",
        "\n",
        "        prediction_with_units = f\"{prediction:.2f} hg/ha\" \n",
        "        return prediction_with_units\n",
        "    except Exception as e:\n",
        "        print(f\"Error in prediction: {e}\")\n",
        "        raise e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example test\n",
        "test_prediction = predict_yield(\"Wheat\", 100, \"Ecuador\", 20, 25)\n",
        "print(test_prediction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Creating Gradio Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extracting unique values for 'country' and 'crop' columns so we can display them in the dropdown as options\n",
        "unique_countries = df['country'].unique().tolist()\n",
        "unique_crop_types = df['crop'].unique().tolist()\n",
        "\n",
        "# Sorting lists\n",
        "unique_countries.sort()\n",
        "unique_crop_types.sort()\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict_yield,\n",
        "    inputs=[\n",
        "        gr.Dropdown(choices=unique_crop_types, label=\"Crop Type\"),\n",
        "        gr.Number(label=\"Rainfall (mm)\"),\n",
        "        gr.Dropdown(choices=unique_countries, label=\"Country\"),\n",
        "        gr.Number(label=\"Pesticides (tonnes)\"),\n",
        "        gr.Number(label=\"Average Temperature (°C)\")\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"Crop Yield Prediction\",\n",
        "    description=\"Select the parameters to predict the crop yield.\",\n",
        "    allow_flagging=False\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
